{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import tqdm\n",
    "from scipy.optimize import Bounds, minimize\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.functional import F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intriguing Properties of Neural Networks\n",
    "There are two types of adversarial models that we will create. The first is a non-specific misclassification and the second is a targeted misclassification. Lastly we will test the cross-model susceptibility.\n",
    "\n",
    "### Part 1: Non-targeted Examples\n",
    "The following cell is group of helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_dataset(torchvision_dataset):\n",
    "    save_dir = \"./data\"\n",
    "    transform_list = [transforms.ToTensor()]\n",
    "    transform = transforms.Compose(transform_list)\n",
    "    kwargs = {\n",
    "        \"download\": True,\n",
    "        \"transform\": transform,\n",
    "    }\n",
    "    train = torchvision_dataset(save_dir, train=True, **kwargs)\n",
    "    test = torchvision_dataset(save_dir, train=False, **kwargs)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def resize_dataset(dataset, dataset_len=None):\n",
    "    if dataset_len is None:\n",
    "        return dataset\n",
    "    assert 0 <= dataset_len <= len(dataset)\n",
    "    ignored_len = len(dataset) - dataset_len\n",
    "    sizes = (dataset_len, ignored_len)\n",
    "    dataset, ignored = random_split(dataset, sizes)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def make_batches(train, test, batch_size=100):\n",
    "    assert 1 <= batch_size <= len(test)\n",
    "    kwargs = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"shuffle\": True,\n",
    "    }\n",
    "    train_loader = DataLoader(train, **kwargs)\n",
    "    test_loader = DataLoader(test, **kwargs)\n",
    "    return train_loader, test_loader\n",
    "    \n",
    "def train_model(model, device, train_loader, optimizer, criterion, num_epochs=1):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Training Epoch\", epoch)\n",
    "        for i, (images, targets) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def test_model(model, device, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, targets) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Prediction\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition\n",
    "This is our convolutional network that we use to train both our adversarial and non-adversarial models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_Net(nn.Module):\n",
    "    def __init__(self, in_height, in_width, num_targets):\n",
    "        super().__init__()\n",
    "        # Convolutional parameters\n",
    "        kernel_size = 4\n",
    "        stride = 1\n",
    "\n",
    "        # Pool layer and its parameters\n",
    "        pool_kernel_size = 2\n",
    "        pool_stride = pool_kernel_size # When these values are the same it reduces the image by half\n",
    "        self.pool = nn.MaxPool2d(pool_kernel_size, pool_stride)\n",
    "\n",
    "        in_channels_2 = 1\n",
    "        out_channels_2 = 10\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels_2,\n",
    "            out_channels_2, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=stride, \n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels_2)\n",
    "\n",
    "        self.conv2_height = height - kernel_size + 1\n",
    "        self.conv2_width = width - kernel_size + 1\n",
    "        self.conv2_size = self.conv2_height * self.conv2_width * out_channels_2\n",
    "\n",
    "        self.pool1_height = int(self.conv2_height / pool_kernel_size)\n",
    "        self.pool1_width = int(self.conv2_height / pool_kernel_size)\n",
    "        self.pool1_size = self.pool1_height * self.pool1_width * out_channels_2\n",
    "\n",
    "        out_channels_3 = 10\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            out_channels_2, \n",
    "            out_channels_3, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=stride, \n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels_3)\n",
    "\n",
    "        self.conv3_height = self.pool1_height - kernel_size + 1\n",
    "        self.conv3_width = self.pool1_width - kernel_size + 1\n",
    "        self.conv3_size = self.conv3_height * self.conv3_width * out_channels_3\n",
    "\n",
    "        self.pool2_height = int(self.conv3_height / pool_kernel_size)\n",
    "        self.pool2_width = int(self.conv3_height / pool_kernel_size)\n",
    "        self.pool2_size = self.pool2_height * self.pool2_width * out_channels_2\n",
    "\n",
    "        in_features_4 = self.pool2_size\n",
    "        out_features_4 = int(in_features_4 / 2)\n",
    "        self.fc1 = nn.Linear(in_features_4, out_features_4)\n",
    "        self.bn4 = nn.BatchNorm1d(out_features_4)\n",
    "\n",
    "        out_features_5 = int(out_features_4 / 2)\n",
    "        self.fc2 = nn.Linear(out_features_4, out_features_5)\n",
    "        self.bn5 = nn.BatchNorm1d(out_features_5)\n",
    "\n",
    "        self.fc3 = nn.Linear(out_features_5, num_targets)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First convolution and pooling\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        # Second convolution and pooling\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        # Flattening convolutional layer for fully connected layer\n",
    "        batch_size = -1\n",
    "        x = x.view(batch_size, self.pool2_size) # This value was calculated in __init__\n",
    "\n",
    "        # First fcl\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn4(x)\n",
    "\n",
    "        # Second fcl\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn5(x)\n",
    "       \n",
    "        # Output fcl\n",
    "        x = self.fc3(x)   \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-adversarial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "torchvision_dataset = datasets.MNIST\n",
    "train, test = load_dataset(torchvision_dataset)\n",
    "\n",
    "# Find dimensions\n",
    "height, width = train.data[0].shape\n",
    "num_targets = len(set(train.targets.numpy()))\n",
    "\n",
    "# Setting the size to \"None\" will use all instances\n",
    "train_len, test_len = 8000, 2000\n",
    "train = resize_dataset(train, train_len)\n",
    "test = resize_dataset(test, test_len)\n",
    "\n",
    "# Batch\n",
    "batch_size = 100\n",
    "train_loader, test_loader = make_batches(train, test, batch_size)\n",
    "\n",
    "# Make model\n",
    "good_model = Conv_Net(height, width, num_targets).to(device)\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(good_model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train\n",
    "num_epochs = 2\n",
    "train_model(good_model, device, train_loader, optimizer, criterion, num_epochs)\n",
    "\n",
    "# Test\n",
    "accuracy = test_model(good_model, device, test_loader)\n",
    "print(f\"Original Accuracy: {accuracy} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "# This is the length of the epsilon_list you are going to create. If your list is longer or shorter you must reflect that change in this variable.\n",
    "num_epsilons = 5 \n",
    "\n",
    "# Make a list of epsilon values for the attack\n",
    "epsilon_list = [i / (num_epsilons * 2) for i in range(num_epsilons)]\n",
    "\n",
    "# This is storage for samples from our adversarial model.\n",
    "examples = {\n",
    "    epsilon: {\n",
    "        \"original_images\": [],\n",
    "        \"adversarial_images\": [],\n",
    "        \"original_predictions\": [],\n",
    "        \"adversarial_predictions\": []\n",
    "    }\n",
    "    for epsilon in epsilon_list\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Below you will set the clamp min and max values on the line \"torch.clamp(perturbated_images, clamp_min, clamp_max)\". Why do we need to clamp and what would the effect of using a value outside the range be?\n",
    "\n",
    "A:\n",
    "    \n",
    "Q: This is very subtle. Why are we adding our perturbations instead of subtracting them? The goal should be to go in the opposite direction of the gradient. How is addition moving us uphill?\n",
    "\n",
    "A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epsilon in epsilon_list:\n",
    "    print(f\"Epsilon: {epsilon}\")\n",
    "    \n",
    "    # Train Attack model\n",
    "    attack_model = Conv_Net(height, width, num_targets).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(attack_model.parameters(), lr = learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_model(attack_model, device, train_loader, optimizer, criterion, num_epochs)\n",
    "    pre_attack_accuracy = test_model(attack_model, device, test_loader)\n",
    "    print(f\"Pre-attack Accuracy: {pre_attack_accuracy} %\")\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sample = True \n",
    "    \n",
    "    for i, (images, targets) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        # Enable finding gradient w.r.t the inputs.\n",
    "        images.requires_grad = True \n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = attack_model(images)\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        image_grad = images.grad \n",
    "\n",
    "        grad_sign = image_grad.sign()\n",
    "        perturbation = ??? # TODO\n",
    "        perturbed_images = ??? # TODO\n",
    "        clamp_min = ??? # TODO\n",
    "        clamp_max = ??? # TODO\n",
    "        perturbed_images = torch.clamp(perturbed_images, clamp_min, clamp_max)\n",
    "\n",
    "        attack_output = attack_model(perturbed_images)\n",
    "        attack_predicted = torch.argmax(attack_output, 1)\n",
    "        \n",
    "        total += targets.size(0)\n",
    "        correct += (attack_predicted == targets).sum().item()\n",
    "        \n",
    "        if sample:\n",
    "            sample = False\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                examples[epsilon][\"original_images\"] = images.cpu().numpy()[:num_epsilons]\n",
    "                examples[epsilon][\"adversarial_images\"] = perturbed_images.cpu().numpy()[:num_epsilons]\n",
    "                examples[epsilon][\"original_predictions\"] = predicted.cpu().numpy()[:num_epsilons]\n",
    "                examples[epsilon][\"adversarial_predictions\"] = attack_predicted.cpu().numpy()[:num_epsilons]\n",
    "            \n",
    "        \n",
    "    post_attack_accuracy = correct / total * 100\n",
    "    print(f\"Post-attack Accuracy: {post_attack_accuracy} %\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: If you were a real attacker that relied on misclassification, how would you deal with the cases where the class was retained?\n",
    "\n",
    "A:\n",
    "\n",
    "Q: Go back and look at where we set grad_sign. If we had multiplied the gradient instead of the gradient sign by the epsilon value our performance would not be as high. Why?\n",
    "\n",
    "A:\n",
    "\n",
    "Q: Our purturbations depended on the gradient of the image. Why is the gradient necessary as opposed to some non-gradient dependent function the input image?\n",
    "\n",
    "A:\n",
    "\n",
    "Q: You can misclassify an image by just mutating it. What is the point of this model? \n",
    "\n",
    "A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot sample of adversarial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dim = 10, 12\n",
    "plt.figure(figsize=plot_dim)\n",
    "\n",
    "plot_index = 1\n",
    "for row in range(num_epsilons):\n",
    "    for column in range(num_epsilons):\n",
    "        plt.subplot(num_epsilons, num_epsilons, plot_index)\n",
    "\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "\n",
    "        epsilon = epsilon_list[row]\n",
    "        if column == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilon), fontsize=14)\n",
    "\n",
    "        adversarial_image = examples[epsilon][\"adversarial_images\"][column].squeeze()\n",
    "        original_prediction = examples[epsilon][\"original_predictions\"][column].item()\n",
    "        adversarial_prediction = examples[epsilon][\"adversarial_predictions\"][column].item()\n",
    "\n",
    "        plt.title(\"{} -> {}\".format(original_prediction, adversarial_prediction))\n",
    "        plt.imshow(adversarial_image, cmap=\"gray\")\n",
    "\n",
    "        plot_index += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Bonus\n",
    "Plot just the purturbations. You can modify the code from the cell above but put the new plotting code in this cell below so that both copies are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Targeted Examples\n",
    "\n",
    "Now we will find inputs that will cause the network to mispredict in such a way that it outputs what we want it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = namedtuple(\n",
    "    \"Config\",\n",
    "    (\n",
    "        \"batch_size\",\n",
    "        \"epochs\",\n",
    "        \"lr\",\n",
    "        \"lr_gamma\",\n",
    "        \"input_size\",\n",
    "        \"output_size\",\n",
    "        \"w_decay\",\n",
    "        \"r_weight\",\n",
    "        \"device\",\n",
    "    )\n",
    ")\n",
    "\n",
    "config = Config(\n",
    "    batch_size=64,\n",
    "    epochs=25,\n",
    "    # Learning rate\n",
    "    lr=1e-4,\n",
    "    # Learning rate decay factor\n",
    "    lr_gamma=0.88,\n",
    "    input_size=28*28,\n",
    "    output_size=10,\n",
    "    # L2 regularization strength\n",
    "    w_decay=1e-4,\n",
    "    # c from section 4.1 of the paper\n",
    "    r_weight=0.15,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "We'll use the full MNIST datasets for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "# MNIST Datasets\n",
    "train_ds = tv.datasets.MNIST(\n",
    "    \"./data\",\n",
    "    transform=tv.transforms.ToTensor(),\n",
    "    train=True,\n",
    "    download=True\n",
    ")\n",
    "test_ds = tv.datasets.MNIST(\n",
    "    \"./data\",\n",
    "    transform=tv.transforms.ToTensor(),\n",
    "    train=False,\n",
    ")\n",
    "# MNIST Data Loaders\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=config.batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "\n",
    "These are some helper functions that you don't need to worry about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, loss_func, loader, config, epoch):\n",
    "    it = tqdm.tqdm(loader, ncols=80, desc=f\"train: {epoch + 1}/{config.epochs}\")\n",
    "    for imgs, targets in it:\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        imgs = imgs.to(config.device).double()\n",
    "        targets = targets.to(config.device)\n",
    "        out = model(imgs)\n",
    "        loss = loss_func(out, targets)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        \n",
    "def test(model, loader, config):\n",
    "    correct = 0\n",
    "    for imgs, targets in tqdm.tqdm(loader, ncols=80, desc=\"Test\"):\n",
    "        model.eval()\n",
    "        imgs = imgs.to(config.device).double()\n",
    "        targets = targets.to(config.device)\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs)\n",
    "            pred = logits_to_label(out)\n",
    "            correct += (pred == targets).sum()\n",
    "    N = len(loader.dataset)\n",
    "    acc = float(correct) / N\n",
    "    print(f\"Test acc: {acc:.02%}\")\n",
    "\n",
    "    \n",
    "def fetch_trained_model(model_class, train_loader, test_loader, load_from_file, path, config):\n",
    "    \"\"\"Either fetch a stored model from disk or train one from scratch\"\"\"\n",
    "    model = model_class(config).double().to(config.device)\n",
    "    if os.path.isfile(path) and load_from_file:\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        test(model, test_loader, config)\n",
    "    else:\n",
    "        opt = torch.optim.Adam(model.parameters(), config.lr, weight_decay=config.w_decay)\n",
    "        # Learning rate adjuster\n",
    "        sched = torch.optim.lr_scheduler.StepLR(opt, 1, config.lr_gamma)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for ep in range(config.epochs):\n",
    "            train(model, opt, criterion, train_loader, config, ep)\n",
    "            test(model, test_loader, config)\n",
    "            sched.step()\n",
    "        torch.save(model.state_dict(), path)\n",
    "    model.eval()\n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "We'll use one of the fully connected models from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_label(logits):\n",
    "    \"\"\"\n",
    "    Converts the logits or log-odds output of the networks\n",
    "    to a class label.\n",
    "    \"\"\"\n",
    "    return torch.softmax(logits, 1).argmax(1)\n",
    "\n",
    "\n",
    "class FCNet100(nn.Module):\n",
    "    \"\"\"The FC100-100-10 network from the paper\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(FCNet100, self).__init__()\n",
    "        self.config = config\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(config.input_size, 100),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Linear(100, 100),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Linear(100, config.output_size),\n",
    "        )\n",
    "        # Note that softmax is left out of the model on purpose.\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x).to(self.config.device)\n",
    "        x = x.view(x.size(0), self.config.input_size)\n",
    "        # Logits\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, a pre-trained set of weights are included in this repository at './data/model_1.pt'.\n",
    "The code below will load them for you. Pass `False` to the `load` argument to train a fresh version\n",
    "of the model. Note that `double()` has been called on the model so that all of the weights are 64-bit floats\n",
    "and the model is expecting 64-bit float inputs. The model will also produce 64-bit floats as outputs.\n",
    "This last part is why `double()` is called and is important later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load our first model from disk or train a fresh one\n",
    "model = fetch_trained_model(\n",
    "    FCNet100,\n",
    "    train_dl,\n",
    "    test_dl,\n",
    "    True,\n",
    "    \"./data/model_1.pt\",\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Adversarial Examples\n",
    "\n",
    "The two functions below are used to find targeted examples. Together these make up the algorithm\n",
    "descriibed in Section 4.1 of the paper:\n",
    "\n",
    "$$\\textrm{minimize} \\quad c \\left\\lvert r \\right\\rvert + \\textrm{loss}_f(x + r, l)$$\n",
    "with $$x + r \\in [0, 1]^m$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_penalty_func(x_plus_r, *args):\n",
    "    \"\"\"This function is simply the penalty from Section 4.1\"\"\"\n",
    "    x, net, c, target, device = args\n",
    "    #\n",
    "    # TODO: fill in the missing part of the penalty\n",
    "    # c|r| penalty portion\n",
    "    size_penalty = c * ???\n",
    "    # x + r as a tensor\n",
    "    x_plus_r_tensor = torch.tensor(x_plus_r.reshape(1, 28, 28)).to(device)\n",
    "    # loss_f(x + r, l) penalty\n",
    "    logits = net(x_plus_r_tensor)\n",
    "    #\n",
    "    # TODO: What loss function should go here?\n",
    "    class_penalty = nn.functional.???(logits, target).item()\n",
    "    #\n",
    "    # TODO: what should be returned\n",
    "    return ???\n",
    "\n",
    "\n",
    "def find_adversarial_example(\n",
    "    net, x, target, config, max_iterations=45_000, max_penalty_function_calls=45_000\n",
    "):\n",
    "    \"\"\"This is the optimization problem described in Section 4.1\"\"\"\n",
    "    # The c weight for the L1 norm of r\n",
    "    c = config.r_weight\n",
    "    # Box constraint: [0, 1]^m\n",
    "    box_constraint = Bounds(np.zeros_like(x.ravel()), np.ones_like(x.ravel()))\n",
    "    # Target label as tensor\n",
    "    target = torch.tensor([target]).to(config.device, dtype=torch.int64)\n",
    "    # Args that will be passed to the penalty function in addition to the (x + r) array.\n",
    "    args = (x.flatten(), net, c, target, device)\n",
    "    #\n",
    "    # TODO: What should the initial guess for x+r be?\n",
    "    #\n",
    "    x_plus_r_initial = ???\n",
    "    \n",
    "    # minimize will be calling the penalty function, and in turn the model, a LOT.\n",
    "    # We use torch.no_grad() to make sure that we don't have the overhead of\n",
    "    # torch's autograd during those calls.\n",
    "    with torch.no_grad():\n",
    "        # We'll treat scipy's minimize as a black box and simply use it as a means to an\n",
    "        # end. Below, we have used the recommended settings for \"L-BFGS-B\" from the\n",
    "        # scipy docs.\n",
    "        res = minimize(\n",
    "            # Our penalty function from above\n",
    "            adv_penalty_func,\n",
    "            # Flatten it since minimize only works on a 1D array\n",
    "            x_plus_r_initial.flatten(),\n",
    "            args,\n",
    "            method='L-BFGS-B',\n",
    "            jac=None,\n",
    "            bounds=box_constraint,\n",
    "            tol=None,\n",
    "            callback=None,\n",
    "            options={\n",
    "                'disp': None,\n",
    "                'maxcor': 10,\n",
    "                'ftol': 2.220446049250313e-09,\n",
    "                'gtol': 1e-05,\n",
    "                # This is the step size used by the numerical optimizer\n",
    "                'eps': 1e-9,\n",
    "                # The maximum number of times the penalty func can be called by minimize\n",
    "                'maxfun': max_penalty_function_calls,\n",
    "                # The maximum number of steps taken by minimize\n",
    "                'maxiter': max_iterations,\n",
    "                'iprint': -1,\n",
    "                'maxls': 15,\n",
    "            }\n",
    "        )\n",
    "    # Reshape back into an image\n",
    "    xr = torch.tensor(res.x.reshape(x.shape))\n",
    "    return xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: Now that you have seen the functions used to find the adversarial examples,\n",
    "why is it important for the model to output 64-bit floats?**\n",
    "\n",
    "**Question: Why is x (the original image) the ideal starting point for the optimizer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Images\n",
    "Now we will select some images from the test dataset, which the model hasn't seen, to turn into adversarial\n",
    "examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select N images that the model correctly classifies already\n",
    "N = 16\n",
    "adv_target = 8\n",
    "x_imgs = []\n",
    "x_labels = []\n",
    "for x, label in test_ds:\n",
    "    if label == adv_target:\n",
    "        continue\n",
    "    x = x.to(config.device).double()\n",
    "    # Make sure that the model correctly classifies this x\n",
    "    if (logits_to_label(model(x)) == label).item():\n",
    "        x_imgs.append(x.cpu())\n",
    "        x_labels.append(label)\n",
    "    if len(x_imgs) >= N:\n",
    "        break\n",
    "\n",
    "x_labels = np.array(x_labels).reshape(4, 4)\n",
    "grid = tv.utils.make_grid(x_imgs, nrow=4, pad_value=1)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Original Inputs\")\n",
    "plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "print(x_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Adversaries\n",
    "This code will call the functions above to create adverserial examples. Unfortunately, it\n",
    "runs pretty slowly so it can take some time to find them. You can try adjusting\n",
    "the `max_iterations` and `max_penalty_function_calls` parameters of\n",
    "`find_adversarial_example()` to speed things up. Note that if you lower them too far you\n",
    "will produce poor examples that don't fool the network or that have large distortions. You can\n",
    "also adjust c to weight the size of r more or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_imgs = []\n",
    "xr_labels = []\n",
    "for x in tqdm.tqdm(x_imgs, ncols=80):\n",
    "    xr = find_adversarial_example(model, x.numpy(), adv_target, config)\n",
    "    xr_imgs.append(xr)\n",
    "    new_label = logits_to_label(model(xr.to(config.device))).item()\n",
    "    xr_labels.append(new_label)\n",
    "xr_labels = np.array(xr_labels).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Results\n",
    "\n",
    "If everything is working properly, all of the new images should be classified as the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = tv.utils.make_grid(xr_imgs, nrow=4, pad_value=1)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Adversarial Examples\")\n",
    "plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "print(f\"New Labels:\\n{xr_labels}\")\n",
    "\n",
    "# Calculate r = (x + r) - x and display them\n",
    "r_imgs = [xr - x for xr, x in zip(xr_imgs, x_imgs)]\n",
    "grid = tv.utils.make_grid(r_imgs, nrow=4, pad_value=1)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Adversarial Perturbations\")\n",
    "plt.imshow(np.transpose(grid, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Network Attack\n",
    "Now we'll try using the examples created using one network to attack another.\n",
    "Below is a model similar to the one used above that has pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNet200(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(FCNet200, self).__init__()\n",
    "        self.config = config\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(config.input_size, 200),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Linear(200, 200),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Linear(200, config.output_size),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x).to(self.config.device)\n",
    "        x = x.view(x.size(0), self.config.input_size)\n",
    "        # Logits\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the pre-trained weights for the model above. If you change the `True` to `False`\n",
    "it will train the model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2 = fetch_trained_model(\n",
    "    FCNet200,\n",
    "    train_dl,\n",
    "    test_dl,\n",
    "    True,\n",
    "    \"./data/model_2.pt\",\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_model_labels = []\n",
    "for xr in x_plus_r_imgs:\n",
    "    label = logits_to_label(model2(xr.unsqueeze(0).to(config.device))).item()\n",
    "    cross_model_labels.append(label)\n",
    "cross_model_labels = np.array(cross_model_labels).reshape(4, 4)\n",
    "\n",
    "print(f\"Cross Model Adverserial Predictions:\\n{cross_model_labels}\")\n",
    "print(f\"Attack Success: {(cross_model_labels == xr_labels).sum() / N:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus: Try experimenting with the second model's architecture to see if it affects the attack\n",
    "success rate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
